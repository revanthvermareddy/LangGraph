{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding LLM Call\n",
    "\n",
    "Let's make the first node as an \"Agent\" that can call OpenAI models using langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (0.1.12)\n",
      "Requirement already satisfied: langchain_openai in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (0.0.8)\n",
      "Requirement already satisfied: python-dotenv in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (0.0.28)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (0.1.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (0.1.24)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain_openai) (1.13.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the API keys for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load env variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# accessing the env variables using os.environ\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# set the model as ChatOpenAI\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Parse the city mentioned\n",
    "\n",
    "extract the city that the user mentions in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def function_1(input_1):\n",
    "    complete_query = f\"\"\"Your task is to provide only the city name based on the user query. \n",
    "    Nothing more, just the city name mentioned. \n",
    "    Following is the user query: {input_1}\"\"\"\n",
    "    response = model.invoke(complete_query)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    return f\"Agent Says: {input_2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a langchain graph\n",
    "\n",
    "from langgraph.graph import Graph\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node('node_1', function_1)\n",
    "workflow.add_node('node_2', function_2)\n",
    "\n",
    "workflow.add_edge('node_1', 'node_2')\n",
    "\n",
    "workflow.set_entry_point('node_1')\n",
    "workflow.set_finish_point('node_2')\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoking the graph with an input\n",
    "\n",
    "# app.invoke(\"What's the temperature in Las Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output at each stage\n",
    "\n",
    "# input = \"Hey there\"\n",
    "# for output in app.stream(input=input):\n",
    "#     # stream() yields dictionaries with output keyed by node name\n",
    "#     for key, val in output.items():\n",
    "#         print(f\"Output from node '{key}':\")\n",
    "#         print('---')\n",
    "#         print(val)\n",
    "#     print('\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Adding a weather API call\n",
    "\n",
    "- We create a new function which take's the city name and gives us the weather for that city.\n",
    "\n",
    "- Open Weather Map is [integrated](https://python.langchain.com/docs/integrations/tools/openweathermap) into LangChain.\n",
    "\n",
    "- we need to install pyowm, create an API key on the website of Open Weather Map (which takes a few hours to activate) and then run the cells below to get the weather of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyowm in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from pyowm) (2.31.0)\n",
      "Requirement already satisfied: geojson<3,>=2.3.0 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from pyowm) (2.5.0)\n",
      "Requirement already satisfied: PySocks<2,>=1.7.1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from pyowm) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/revanth/developer/Personal/Langchain/LangGraph/.venv/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "# load env variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# accessing the env variables using os.environ\n",
    "os.environ['OPENWEATHERMAP_API_KEY'] = os.environ.get('OPENWEATHERMAP_API_KEY')\n",
    "\n",
    "weather = OpenWeatherMapAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_name = 'Las Vegas'\n",
    "# weather_data = weather.run(city_name)\n",
    "# print(f'The weather data at city [{city_name}] is: {weather_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def function_1(input_1):\n",
    "    complete_query = f\"\"\"Your task is to provide only the city name based on the user query. \n",
    "    Nothing more, just the city name mentioned. \n",
    "    Following is the user query: {input_1}\"\"\"\n",
    "    response = model.invoke(complete_query)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    weather_data = weather.run(input_2)\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate this into function 2 and call the function 2 as a \"tool\" or \"weather_Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a langchain graph\n",
    "\n",
    "from langgraph.graph import Graph\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node('agent', function_1)\n",
    "workflow.add_node('tool', function_2)\n",
    "\n",
    "workflow.add_edge('agent', 'tool')\n",
    "\n",
    "workflow.set_entry_point('agent')\n",
    "workflow.set_finish_point('tool')\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.invoke(\"What's the temperature in Las Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output at each stage\n",
    "\n",
    "# input = \"What's the temperature in Las Vegas\"\n",
    "# for output in app.stream(input=input):\n",
    "#     # stream() yields dictionaries with output keyed by node name\n",
    "#     for key, val in output.items():\n",
    "#         print(f\"Output from node '{key}':\")\n",
    "#         print('---')\n",
    "#         print(val)\n",
    "#     print('\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Adding another LLM Call to filter results\n",
    "\n",
    "Here we only want the temperature but the current sentup gives us the full weather report.\n",
    "\n",
    "So we can make another LLM call to filter data.\n",
    "\n",
    "Also, we can use a dictionary and pass it between the nodes (we could also use list but dict makes it a bit easier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign AgentState as an empty dict\n",
    "AgentState = {}\n",
    "\n",
    "# messages key will be assigned as an empty array. we will append new messages as we pass along nodes.\n",
    "AgentState['messages'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to have this state filler as: {'messages': [HumanMessage, AIMessage, ...]}\n",
    "\n",
    "Also now we need to modify our functions to pass info along the new AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def function_1(state):\n",
    "    messages = state['messages']\n",
    "    user_input = messages[-1]\n",
    "    complete_query = f\"\"\"Your task is to provide only the city name based on the user query. \n",
    "    Nothing more, just the city name mentioned. \n",
    "    Following is the user query: {user_input}\"\"\"\n",
    "    response = model.invoke(complete_query)\n",
    "    state['messages'].append(response.content)  # Appending AIMessage response\n",
    "    return state\n",
    "\n",
    "def function_2(state):\n",
    "    messages = state['messages']\n",
    "    agent_response = messages[-1]\n",
    "    weather = OpenWeatherMapAPIWrapper()\n",
    "    weather_data = weather.run(agent_response)\n",
    "    state['messages'].append(weather_data)\n",
    "    return state\n",
    "\n",
    "def function_3(state):\n",
    "    messages = state['messages']\n",
    "    user_input = messages[0]\n",
    "    available_info = messages[-1]\n",
    "    complete_query = f\"\"\"Your task is to provide info concisely based on the user query and the available information from the internet.\n",
    "    Following is the user query: \"{user_input}\", Available information: \"{available_info}\"\n",
    "    \"\"\"\n",
    "    # return complete_query\n",
    "    reponse = model.invoke(complete_query)\n",
    "    return reponse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a langchain graph\n",
    "\n",
    "from langgraph.graph import Graph\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node('agent', function_1)\n",
    "workflow.add_node('tool', function_2)\n",
    "workflow.add_node('responder', function_3)\n",
    "\n",
    "workflow.add_edge('agent', 'tool')\n",
    "workflow.add_edge('tool', 'responder')\n",
    "\n",
    "workflow.set_entry_point('agent')\n",
    "workflow.set_finish_point('responder')\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature in Las Vegas is 10.95°C with scattered clouds. The high is 11.8°C and the low is 10.2°C. The temperature feels like 9.98°C with a wind speed of 13.86 m/s and 40% cloud cover.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {'messages': [\"What's the temperature in Las Vegas\"]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [\"What's the temperature in Las Vegas\", 'Las Vegas']}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tool':\n",
      "---\n",
      "{'messages': [\"What's the temperature in Las Vegas\", 'Las Vegas', 'In Las Vegas, the current weather is as follows:\\nDetailed status: scattered clouds\\nWind speed: 13.86 m/s, direction: 50°\\nHumidity: 72%\\nTemperature: \\n  - Current: 11.0°C\\n  - High: 11.8°C\\n  - Low: 10.2°C\\n  - Feels like: 10.04°C\\nRain: {}\\nHeat index: None\\nCloud cover: 40%']}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'responder':\n",
      "---\n",
      "The current temperature in Las Vegas is 11.0°C with scattered clouds. The high temperature is 11.8°C and the low is 10.2°C. The humidity is at 72% with a wind speed of 13.86 m/s. The weather feels like 10.04°C with a cloud cover of 40%.\n",
      "\n",
      "---\n",
      "\n",
      "Output from node '__end__':\n",
      "---\n",
      "The current temperature in Las Vegas is 11.0°C with scattered clouds. The high temperature is 11.8°C and the low is 10.2°C. The humidity is at 72% with a wind speed of 13.86 m/s. The weather feels like 10.04°C with a cloud cover of 40%.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the output at each stage\n",
    "\n",
    "input = {'messages': [\"What's the temperature in Las Vegas\"]}\n",
    "for output in app.stream(input=input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, val in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print('---')\n",
    "        print(val)\n",
    "    print('\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice that there is a lot of appending to the array going on, we can make it a bit easier with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a virtual assistant, so I don't have feelings or emotions. In Istanbul, the current weather is clear with a temperature of 6.95°C, a wind speed of 3.6 m/s, and a humidity of 79%.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"messages\": [\"how are you?\"]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make our agent smarter by saying only use the tool when needed, if not just respond back to the user.\n",
    "\n",
    "1. Building a tool to the agent\n",
    "2. Using a conditional edge to the agent with the option to either call the tool or not\n",
    "3. Defining the criteria for the conditional edge as when to call the tool. We will define a funciton for this.\n",
    "\n",
    "Let's start with the AgentState definition as mentioned a few calls above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building tool with agent (LLM Model) is made easy in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_community.tools.openweathermap import OpenWeatherMapQueryRun\n",
    "\n",
    "tools = [OpenWeatherMapQueryRun()]\n",
    "\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our modified function_1 now becomes as below. The reason is, we are passing the human message as state and appending response to the state. Also, our agent now has a tool bound to it, that it can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For funciton_2, we want to setup a tool and call it. It's made easy to invoke a tool in LangChain by using ToolInvocation and executing it with ToolExecutor. Then we respond back as a FunctionMessage so that our agent (node 1) knows that the tool was used and a response from the tool is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation, ToolExecutor\n",
    "from langchain_core.messages import FunctionMessage\n",
    "import json\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "def funciton_2(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] # this has the query we need to send to the tool\n",
    "    \n",
    "    parsed_tool_input = json.loads(last_message.additional_kwargs['function_call']['arguments'])\n",
    "    \n",
    "    # we construct a ToolInvocation from the funciton_call and pass in the tool name and the expected str input for the OpenWeatherMap tool\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs['function_call']['name'],\n",
    "        tool_input=parsed_tool_input['__arg1']\n",
    "    )\n",
    "    \n",
    "    # we call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    \n",
    "    # we use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    \n",
    "    # we return a list, because this well get added to the existing list\n",
    "    return {'messages': [function_message]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a function for the conditional edge, to help us figure out which direction to go (tool or user response)\n",
    "\n",
    "We can benefit from the agent (LLM) response in LangChain, which has additional_kwargs to make a function_call with the name of the tool.\n",
    "\n",
    "So our logic is, if function_call available in the additional_kwargs, then call tool if not then end the discussion and respond back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_to_go(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if 'function_call' in last_message.additional_kwargs:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with all of the changes above, our LangGraph app is modified as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.graph import Graph, END\n",
    "\n",
    "# workflow = Graph()\n",
    "\n",
    "# Or you could import StateGraph and pass AgentState to it\n",
    "from langgraph.graph import StateGraph, END\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node('agent', function_1)\n",
    "workflow.add_node('tool', funciton_2)\n",
    "\n",
    "# The conditional edge requires the following info below.\n",
    "workflow.add_conditional_edges('agent', where_to_go, {\n",
    "    # based on the return from where_to_go\n",
    "    # if return is \"continue\" then we call the tool node.\n",
    "    \"continue\": \"tool\",\n",
    "    # otherwise we finish. END is a special node marking that the graph should finsh.\n",
    "    \"end\": END\n",
    "})\n",
    "\n",
    "# we now add a normal edge from 'tool' to 'agent'.\n",
    "# this means that if 'tool' is called, then it has to call the 'agent' next.\n",
    "workflow.add_edge('tool', 'agent')\n",
    "\n",
    "# basically, agent node has the option to call a tool node based on a condition,\n",
    "# whereas tool node must call the agent in all cases based on this setup.\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also pass the first message using HumanMessage component avaialable in langchain, makes it easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the temperature in las vegas'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Las Vegas\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call'}),\n",
       "  FunctionMessage(content='In Las Vegas, the current weather is as follows:\\nDetailed status: broken clouds\\nWind speed: 13.86 m/s, direction: 50°\\nHumidity: 65%\\nTemperature: \\n  - Current: 11.96°C\\n  - High: 12.91°C\\n  - Low: 10.93°C\\n  - Feels like: 10.91°C\\nRain: {}\\nHeat index: None\\nCloud cover: 75%', name='open_weather_map'),\n",
       "  AIMessage(content='The current temperature in Las Vegas is 11.96°C. It is partly cloudy with a wind speed of 13.86 m/s and a humidity of 65%.', response_metadata={'finish_reason': 'stop'})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {'messages': [HumanMessage(content='What is the temperature in las vegas')]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Las Vegas\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call'})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tool':\n",
      "---\n",
      "{'messages': [FunctionMessage(content='In Las Vegas, the current weather is as follows:\\nDetailed status: broken clouds\\nWind speed: 13.86 m/s, direction: 50°\\nHumidity: 64%\\nTemperature: \\n  - Current: 12.06°C\\n  - High: 12.91°C\\n  - Low: 10.93°C\\n  - Feels like: 10.99°C\\nRain: {}\\nHeat index: None\\nCloud cover: 75%', name='open_weather_map')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current temperature in Las Vegas is 12.06°C. It feels like 10.99°C with broken clouds and a wind speed of 13.86 m/s.', response_metadata={'finish_reason': 'stop'})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node '__end__':\n",
      "---\n",
      "{'messages': [HumanMessage(content='What is the temperature in las vegas'), AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Las Vegas\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call'}), FunctionMessage(content='In Las Vegas, the current weather is as follows:\\nDetailed status: broken clouds\\nWind speed: 13.86 m/s, direction: 50°\\nHumidity: 64%\\nTemperature: \\n  - Current: 12.06°C\\n  - High: 12.91°C\\n  - Low: 10.93°C\\n  - Feels like: 10.99°C\\nRain: {}\\nHeat index: None\\nCloud cover: 75%', name='open_weather_map'), AIMessage(content='The current temperature in Las Vegas is 12.06°C. It feels like 10.99°C with broken clouds and a wind speed of 13.86 m/s.', response_metadata={'finish_reason': 'stop'})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {'messages': [HumanMessage(content='What is the temperature in las vegas')]}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keys by node name\n",
    "    for key, val in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print('---')\n",
    "        print(val)\n",
    "    print('\\n---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
